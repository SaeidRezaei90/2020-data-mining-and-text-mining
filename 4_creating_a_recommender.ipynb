{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun Time! Application on Recommender Systems\n",
    "\n",
    "We've seen basic operations for loading, filtering, and processing datasets using NumPy, Pandas, and Scipy.\n",
    "\n",
    "Now we've arrived to the fun part. We will be implementing recommender systems using these libraries.\n",
    "\n",
    "We will take into account recommendations at length $n$, i.e., each algorithm will return a list of $n$ items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_csr = sparse.load_npz(\"data/urm_csr.npz\",)\n",
    "urm_csc = sparse.load_npz(\"data/urm_csc.npz\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 944 1683\n"
     ]
    }
   ],
   "source": [
    "recommendation_length = 10\n",
    "(num_users, num_items), num_interactions = urm_csr.shape, urm_csr.nnz\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "print(recommendation_length, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender: Random\n",
    "\n",
    "![Random Recommender](images/random.jpg)\n",
    "\n",
    "The name it's more or less self explanatory. But just to make it clear, it recommends $n$ random items of the catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_item_recommender():\n",
    "    return rng.permutation(np.arange(num_items))[:recommendation_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender: Top Popular\n",
    "\n",
    "This is one of the most basic recommender out there. It just recommend the most popular items to all users.\n",
    "\n",
    "The interesting part is to count the number of times each item has been interacted.\n",
    "\n",
    "When we have a CSC Sparse matrix, we can get the number of elements stored in each column using the `indptr` attribute [Reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix) and the `np.ediff1d` function.\n",
    "\n",
    "More specifically, for a matrix like this:\n",
    "\n",
    "```python\n",
    "[[1, 0, 4],\n",
    " [0, 0, 5],\n",
    " [2, 3, 6]]\n",
    "```\n",
    "We have that `indptr = np.array([0, 2, 3, 6])` (will always have one more column than the original number of columns), `indices = np.array([0, 2, 2, 0, 1, 2])`, and `data = np.array([1, 2, 3, 4, 5, 6])`. If we want to know where in the matrix we have a value, we do the following:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_idx = 0 - row_ranges = array([0, 2], dtype=int32) - values = array([1, 2])\n",
      "column_idx = 1 - row_ranges = array([2], dtype=int32) - values = array([3])\n",
      "column_idx = 2 - row_ranges = array([0, 1, 2], dtype=int32) - values = array([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "example_matrix = sparse.csc_matrix(np.array([[1, 0, 4], [0, 0, 5], [2, 3, 6]]))\n",
    "\n",
    "for column_idx in range(3):\n",
    "    row_ranges = example_matrix.indices[example_matrix.indptr[column_idx]:example_matrix.indptr[column_idx+1]]\n",
    "    values = example_matrix.data[example_matrix.indptr[column_idx]:example_matrix.indptr[column_idx+1]]\n",
    "    print(f\"{column_idx = } - {row_ranges = } - {values = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the way indptr is constructed, we can deduct that the number of non zero elements on each column $i$ is solely the difference between `indptr[i+1] - indptr[i]`. Moreover, after we've calculated the number of nnz elements in each column, we sort the indices with `np.argsort` and get the latest $n$ indices (argsort sorts in ascending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_popular_item_recommender():\n",
    "    return np.argsort(np.ediff1d(urm_csc.indptr))[num_items - 1: num_items - 1 - recommendation_length:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "**DISCLAIMER**: I'm not the author of this cheat sheet. All credits go to their respective authors.\n",
    "\n",
    "![Nice NumPy Cheat Sheet](images/numpy_cheat_sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "**DISCLAIMER**: I'm not the author of this cheat sheet. All credits go to their respective authors.\n",
    "\n",
    "![Nice Pandas Cheat Sheet](images/pandas_cheat_sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "\n",
    "**DISCLAIMER**: I'm not the author of this cheat sheet. All credits go to their respective authors.\n",
    "\n",
    "![Nice Pandas Cheat Sheet](images/scipy_cheat_sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some exercises for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "1. What is the difference between `np.loadtxt` and `np.genfromtxt`\n",
    "2. What does the `np.vectorize` function do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "1. What is the main benefit of using pandas readers for files, such as read_csv, read_excel, instead of np.loadtxt? What are some limitations that we find in Numpy?\n",
    "2. Can we create a new column using the attribute notation? i.e. can we do this? `data_df.new_col = <series>` If not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy\n",
    "\n",
    "1. What do you think could be the use of a LiL matrix? What are the differences between a Python Dictionary and a sparse matrix? Can they be equivalent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "NumPy is **THE** foundation of all the data science stack in Python. Most of the libraries are built on top of NumPy data structures. Make sure you take your time to understand them.\n",
    "\n",
    "The basic data structure of NumPy is an `n-array`, i.e., an array of `n` dimensions with **LOTS** of methods to work with these arrays.\n",
    "\n",
    "NumPy is really important in the field because it is **FAST**, most of the routines are implemented in C and you can get orders of magnitude faster than with their Python counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Â Convention, just memorize that np.<something> means a numpy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have to think in vectors\n",
    "\n",
    "Most of the operations are highly optimized to be done in a vectorized way (e.g. no `for` loops). \n",
    "\n",
    "Let's see an example of this. First we will prepare four arrays.\n",
    "\n",
    "Two arrays will be implemented as Python `lists` (`huge_array_1` & `huge_array_2`) and two arrays will be NumPy `arrays` (`numpy_huge_array_1` & `numpy_huge_array_2`). We will see the difference in speed by measuring two things: \n",
    "\n",
    "1. Data structure efficiency\n",
    "2. Algorithm \"efficiency\"\n",
    "\n",
    "We're not going to do something uterly complicated here. We are just going to sum both arrays ðŸ˜…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "huge_array_1 = [x for x in range(10000000)]\n",
    "huge_array_2 = [x*x for x in range(10000000)]\n",
    "\n",
    "numpy_huge_array_1 = np.array(huge_array_1)\n",
    "numpy_huge_array_2 = np.array(huge_array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_naive_python_loop():\n",
    "    a = []\n",
    "    for arr1, arr2 in zip(huge_array_1, huge_array_2):\n",
    "        a.append(arr1 + arr2)\n",
    "        \n",
    "def sum_naive_python_list_comprehension():\n",
    "    a = [arr1 + arr2 for arr1, arr2 in zip(huge_array_1, huge_array_2)]\n",
    "    \n",
    "def sum_naive_numpy_loop():\n",
    "    a = []\n",
    "    for arr1, arr2 in zip(numpy_huge_array_1, numpy_huge_array_2):\n",
    "        a.append(arr1 + arr2)\n",
    "        \n",
    "def sum_naive_numpy_list_comprehension():\n",
    "    a = [arr1 + arr2 for arr1, arr2 in zip(numpy_huge_array_1, numpy_huge_array_2)]\n",
    "    \n",
    "def sum_numpy_approved():\n",
    "    a = numpy_huge_array_1 + numpy_huge_array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super naive Python for loop with Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 s Â± 23.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1.02 s Â± 12.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "3.55 s Â± 196 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "3.18 s Â± 43.9 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "26.6 ms Â± 125 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_naive_python_loop()\n",
    "%timeit sum_naive_python_list_comprehension()\n",
    "%timeit sum_naive_numpy_loop()\n",
    "%timeit sum_naive_numpy_list_comprehension()\n",
    "%timeit sum_numpy_approved()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheat Sheets for ya\n",
    "\n",
    "Some people like to have everything condensed into a single PDF that you can check whenever you've a doubt. So, here you have them ðŸ‘Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "\n",
    "**DISCLAIMER**: I'm not the author of this cheat sheet. All credits go to their respective authors.\n",
    "\n",
    "![Nice Pandas Cheat Sheet](images/matplotlib_cheat_sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
